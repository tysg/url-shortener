
user  nginx;
worker_processes  1;

error_log  /var/log/nginx/nginx.error.log warn;
pid        /var/run/nginx.pid;


events {
    worker_connections 1024; # increase if you have lots of clients
    accept_mutex off; # set to 'on' if nginx worker_processes > 1
    # 'use epoll;' to enable for Linux 2.6+
    # 'use kqueue;' to enable for FreeBSD, OSX   worker_connections  1024;
}


http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for" $request_time';

    access_log  /var/log/nginx/nginx.access.log  main;

    sendfile        on;
    #tcp_nopush     on;

    keepalive_timeout  65;

    #gzip  on;

    #include /etc/nginx/conf.d/*.conf;
    upstream app_server {

        # fail_timeout=0 means we always retry an upstream even if it failed
        # to return a good HTTP response

        # for UNIX domain socket setups
        server short-url:5000 fail_timeout=0;

        # for a TCP configuration
        # server 192.168.0.7:8000 fail_timeout=0;
    }

    server {
        # use 'listen 80 deferred;' for Linux
        # use 'listen 80 accept_filter=httpready;' for FreeBSD
        listen 80 default_server;
        client_max_body_size 4G;

        # set the correct host(s) for your site
        #server_name example.com www.example.com;

        keepalive_timeout 5;

        location / {
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Host $http_host;
            # we don't want nginx trying to do something clever with
            # redirects, we set the Host: header above already.
            proxy_redirect off;
            proxy_pass http://app_server;
        }
    }
}
